{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55655e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching articles from Smart Home News (https://www.pcmag.com/news/categories/smart-home)\n",
      "Fetching articles from Smart Home Products (https://www.pcmag.com/picks/categories/smart-home?test_uuid=03iF1uOjHbmoZSTXr58OMhT&test_variant=A)\n",
      "Found 40 unique article URLs\n",
      "\n",
      "Scraping 40 articles...\n",
      "\n",
      "[1/40] Scraping: https://www.pcmag.com/news/judge-axes-police-program-which-monitored-sacramento-residents-electricity [Smart Home News]\n",
      "[2/40] Scraping: https://www.pcmag.com/news/robot-vacuum-mop-early-black-friday-2025-deals-irobot-ecovacs-nov-22 [Smart Home News]\n",
      "[3/40] Scraping: https://www.pcmag.com/news/your-security-camera-may-soon-work-with-more-apps-thanks-to-matter-15 [Smart Home News]\n",
      "[4/40] Scraping: https://www.pcmag.com/news/best-robot-vacuum-mop-early-black-friday-2025-deals-irobot-shark-nov-18 [Smart Home News]\n",
      "[5/40] Scraping: https://www.pcmag.com/news/google-pulls-the-plug-on-older-nest-thermostats-5-alternatives-we-recommend [Smart Home News]\n",
      "[6/40] Scraping: https://www.pcmag.com/news/community-project-wants-to-revive-older-bricked-nest-learning-thermostats [Smart Home News]\n",
      "[7/40] Scraping: https://www.pcmag.com/news/early-black-friday-yeedi-s14-plus-robot-vacuum-and-mop-deal-54-off [Smart Home News]\n",
      "[8/40] Scraping: https://www.pcmag.com/news/neato-u-turns-on-support-for-its-robot-vacuums-buyers-arent-happy [Smart Home News]\n",
      "[9/40] Scraping: https://www.pcmag.com/news/this-weeks-aws-crash-made-smart-beds-overheat-get-stuck-in-wrong-position [Smart Home News]\n",
      "[10/40] Scraping: https://www.pcmag.com/news/this-new-smart-litter-tray-uses-ai-to-monitor-your-cats-health [Smart Home News]\n",
      "[11/40] Scraping: https://www.pcmag.com/news/ring-wants-you-to-share-your-camera-footage-with-police-again [Smart Home News]\n",
      "[12/40] Scraping: https://www.pcmag.com/news/best-robot-vacuum-mop-deals-amazon-prime-day-oct-2025-still-available [Smart Home News]\n",
      "[13/40] Scraping: https://www.pcmag.com/news/best-robot-vacuum-mops-deals-amazon-prime-day-oct-2025-day-2 [Smart Home News]\n",
      "[14/40] Scraping: https://www.pcmag.com/news/google-hints-at-a-future-nest-hub-smart-display-with-gemini [Smart Home News]\n",
      "[15/40] Scraping: https://www.pcmag.com/news/best-robot-vacuum-mops-deals-amazon-prime-day-oct-07-2025 [Smart Home News]\n",
      "[16/40] Scraping: https://www.pcmag.com/news/robot-vacuum-and-mop-deals-canada-october-prime-day-2025 [Smart Home News]\n",
      "[17/40] Scraping: https://www.pcmag.com/news/its-halloween-time-to-scare-your-neighbors-with-this-creepy-6-foot-skeleton [Smart Home News]\n",
      "[18/40] Scraping: https://www.pcmag.com/news/amazon-fall-2025-event-how-to-order-every-new-echo-fire-tv-ring-and-blink [Smart Home News]\n",
      "[19/40] Scraping: https://www.pcmag.com/news/everything-amazon-announced-2025-fall-devices-event-scribe-ring-echo-fire [Smart Home News]\n",
      "[20/40] Scraping: https://www.pcmag.com/news/google-finally-refreshes-its-home-speakers-nest-cams-with-gemini-inside [Smart Home News]\n",
      "[21/40] Scraping: https://www.pcmag.com/picks/the-best-cheap-robot-vacuums [Smart Home Products]\n",
      "[22/40] Scraping: https://www.pcmag.com/picks/the-best-pet-cameras [Smart Home Products]\n",
      "[23/40] Scraping: https://www.pcmag.com/picks/the-best-smart-bird-feeders [Smart Home Products]\n",
      "[24/40] Scraping: https://www.pcmag.com/picks/the-best-smart-water-leak-detectors [Smart Home Products]\n",
      "[25/40] Scraping: https://www.pcmag.com/picks/the-best-robot-lawn-mowers [Smart Home Products]\n",
      "[26/40] Scraping: https://www.pcmag.com/picks/the-best-self-emptying-robot-vacuums [Smart Home Products]\n",
      "[27/40] Scraping: https://www.pcmag.com/picks/the-best-smart-displays [Smart Home Products]\n",
      "[28/40] Scraping: https://www.pcmag.com/picks/the-best-robot-vacuums-for-pet-hair [Smart Home Products]\n",
      "[29/40] Scraping: https://www.pcmag.com/picks/the-best-robot-pool-cleaners [Smart Home Products]\n",
      "[30/40] Scraping: https://www.pcmag.com/picks/the-best-roomba [Smart Home Products]\n",
      "[31/40] Scraping: https://www.pcmag.com/picks/the-best-digital-picture-frames [Smart Home Products]\n",
      "[32/40] Scraping: https://www.pcmag.com/picks/amazons-echo-lineup-whats-the-difference [Smart Home Products]\n",
      "[33/40] Scraping: https://www.pcmag.com/picks/the-best-smart-locks [Smart Home Products]\n",
      "[34/40] Scraping: https://www.pcmag.com/picks/the-best-smart-thermostats [Smart Home Products]\n",
      "[35/40] Scraping: https://www.pcmag.com/picks/the-best-floodlight-cameras [Smart Home Products]\n",
      "[36/40] Scraping: https://www.pcmag.com/picks/the-best-smart-home-devices [Smart Home Products]\n",
      "[37/40] Scraping: https://www.pcmag.com/picks/the-best-robot-mops [Smart Home Products]\n",
      "[38/40] Scraping: https://www.pcmag.com/picks/the-best-robot-vacuums [Smart Home Products]\n",
      "[39/40] Scraping: https://www.pcmag.com/picks/the-best-outdoor-home-security-cameras [Smart Home Products]\n",
      "[40/40] Scraping: https://www.pcmag.com/picks/the-best-video-doorbells [Smart Home Products]\n",
      "\n",
      "✓ Successfully scraped 40 articles\n",
      "✓ Saved results to c:\\Users\\Admin\\Documents\\VIETTEL\\2-crawl-articles\\output/pcmag_smarthome_20251124_095128.xlsx\n",
      "\n",
      "Breakdown by source:\n",
      "  - Smart Home News: 20 articles\n",
      "  - Smart Home Products: 20 articles\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from urllib.parse import urljoin\n",
    "import time\n",
    "import urllib3\n",
    "import os\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "BASE_URL = \"https://www.pcmag.com/\"\n",
    "NEWS_URLS = {\n",
    "    f\"{BASE_URL}news/categories/smart-home\": \"Smart Home News\",\n",
    "    f\"{BASE_URL}picks/categories/smart-home?test_uuid=03iF1uOjHbmoZSTXr58OMhT&test_variant=A\": \"Smart Home Products\"\n",
    "}\n",
    "\n",
    "EXCLUDE_PATHS = [\n",
    "    '/category/', '/tag/', '/author/', '/wp-admin', '/feed',\n",
    "    '/subscribe', '/contact', '/about', '/privacy', '/terms',\n",
    "    '?s=', '/search', '/newsletter'\n",
    "]\n",
    "\n",
    "\n",
    "# ------------------- SELENIUM SETUP ---------------------\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")\n",
    "chrome_options.add_argument(\"--disable-gpu\")\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64)\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "\n",
    "def fetch_page(url):\n",
    "    \"\"\"Fetch and parse a webpage via Selenium.\"\"\"\n",
    "    try:\n",
    "        driver.get(url)\n",
    "        time.sleep(1.5)\n",
    "        html = driver.page_source\n",
    "        return BeautifulSoup(html, \"html.parser\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def is_valid_article_url(url):\n",
    "    \"\"\"Check if URL is likely an article.\"\"\"\n",
    "    if not url.startswith(BASE_URL):\n",
    "        return False\n",
    "\n",
    "    path = url[len(BASE_URL):]\n",
    "\n",
    "    if len(path) < 10 or path == '/':\n",
    "        return False\n",
    "\n",
    "    if any(excluded in path.lower() for excluded in EXCLUDE_PATHS):\n",
    "        return False\n",
    "\n",
    "    return '-' in path\n",
    "\n",
    "\n",
    "def get_article_links():\n",
    "    \"\"\"Extract article URLs from PCMag Smart Home pages with source tracking.\"\"\"\n",
    "    all_links = {}  # {article_url: {'source': source_name, 'date': date}}\n",
    "\n",
    "    for news_url, source_name in NEWS_URLS.items():\n",
    "        print(f\"Fetching articles from {source_name} ({news_url})\")\n",
    "\n",
    "        soup = fetch_page(news_url)\n",
    "        if not soup:\n",
    "            continue\n",
    "\n",
    "        article_cards = soup.find_all(\"div\", class_=\"flex flex-1 flex-col gap-3\")\n",
    "\n",
    "        for item in article_cards:\n",
    "            h2_tag = item.find(\"h2\", class_=\"font-stretch-ultra-condensed text-lg font-semibold leading-compact md:text-xl\")\n",
    "\n",
    "            if not h2_tag:\n",
    "                continue\n",
    "\n",
    "            a_tag = h2_tag.find(\"a\", href=True)\n",
    "            if not a_tag:\n",
    "                continue\n",
    "\n",
    "            url = urljoin(BASE_URL, a_tag[\"href\"].strip())\n",
    "            if not is_valid_article_url(url):\n",
    "                continue\n",
    "\n",
    "            # Date extraction\n",
    "            parent = item.find_parent()\n",
    "            date_span = parent.find(\"span\", {\"data-content-published-date\": \"\"}) if parent else None\n",
    "            date_text = date_span.get_text(strip=True) if date_span else \"\"\n",
    "\n",
    "            all_links[url] = {\n",
    "                'source': source_name,\n",
    "                'date': date_text\n",
    "            }\n",
    "\n",
    "    print(f\"Found {len(all_links)} unique article URLs\")\n",
    "    return all_links\n",
    "\n",
    "\n",
    "def scrape_article(url, source_name, date_from_listing):\n",
    "    \"\"\"Extract content from a single article.\"\"\"\n",
    "    try:\n",
    "        soup = fetch_page(url)\n",
    "        if not soup:\n",
    "            return None\n",
    "\n",
    "        # Title\n",
    "        title = soup.find(\"h1\")\n",
    "        if not title:\n",
    "            title = soup.find(\"h2\", class_=\"font-stretch-ultra-condensed\")\n",
    "\n",
    "        # Description\n",
    "        description = soup.find(\"meta\", property=\"og:description\")\n",
    "        if description:\n",
    "            description_text = description.get(\"content\", \"\")\n",
    "        else:\n",
    "            desc_tag = soup.find(\"p\", class_=\"line-clamp-2\")\n",
    "            description_text = desc_tag.get_text(strip=True) if desc_tag else \"\"\n",
    "\n",
    "        # Date fallback\n",
    "        date_text = date_from_listing\n",
    "        if not date_text:\n",
    "            date_tag = soup.find(\"time\") or soup.find(\"span\", {\"data-content-published-date\": \"\"})\n",
    "            if date_tag:\n",
    "                date_text = date_tag.get(\"datetime\", date_tag.get_text(strip=True))\n",
    "\n",
    "        return {\n",
    "            \"Nguồn\": source_name,\n",
    "            \"Tiêu đề\": title.get_text(strip=True) if title else \"\",\n",
    "            \"Mô tả\": description_text,\n",
    "            \"Ngày\": date_text,\n",
    "            \"URL\": url\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def main():\n",
    "    articles = []\n",
    "\n",
    "    article_links = get_article_links()\n",
    "\n",
    "    print(f\"\\nScraping {len(article_links)} articles...\\n\")\n",
    "\n",
    "    for i, (url, info) in enumerate(article_links.items(), start=1):\n",
    "        print(f\"[{i}/{len(article_links)}] Scraping: {url} [{info['source']}]\")\n",
    "        data = scrape_article(url, info[\"source\"], info[\"date\"])\n",
    "        if data and data[\"Tiêu đề\"]:\n",
    "            articles.append(data)\n",
    "        time.sleep(1)\n",
    "\n",
    "    # Save file\n",
    "    output_dir = r\"C:\\Users\\Admin\\Documents\\VIETTEL\\2-crawl-articles\\scraper\\output-scraper\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    if articles:\n",
    "        df = pd.DataFrame(articles)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        excel_file = f\"{output_dir}/pcmag_smarthome_{timestamp}.xlsx\"\n",
    "        df.to_excel(excel_file, index=False)\n",
    "\n",
    "        print(f\"\\n✓ Successfully scraped {len(articles)} articles\")\n",
    "        print(f\"✓ Saved results to {excel_file}\")\n",
    "\n",
    "        print(\"\\nBreakdown by source:\")\n",
    "        for source, count in df[\"Nguồn\"].value_counts().items():\n",
    "            print(f\"  - {source}: {count} articles\")\n",
    "    else:\n",
    "        print(\"\\n✗ No articles were successfully scraped.\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
